# üîß GUIDE : APPLICATION DES MODIFICATIONS AU NOTEBOOK

## üìã **√âTAPES √Ä SUIVRE**

### **1. Ouvrir le Notebook**
```bash
jupyter notebook Yshop.ipynb
```
ou depuis VS Code : ouvrir directement `Yshop.ipynb`

### **2. Modifications √† Appliquer**

#### **A. Localiser la cellule de mod√©lisation (section 4.2)**
Cherchez la cellule qui commence par :
```python
# 4.2 Entra√Ænement des mod√®les de Machine Learning
```

#### **B. Remplacer ENTI√àREMENT cette cellule par le code corrig√© :**

```python
# 4.2 Entra√Ænement des mod√®les de Machine Learning CORRIG√â
print("ü§ñ ENTRA√éNEMENT DES MOD√àLES DE MACHINE LEARNING")
print("=" * 50)

# üîç DIAGNOSTIC ET CORRECTION DU SURAPPRENTISSAGE
print("üîç DIAGNOSTIC: V√©rification des features...")

# Pr√©paration S√âCURIS√âE des donn√©es pour l'entra√Ænement
target = modeling_data['revenue']

# ‚ö†Ô∏è CORRECTION: Exclusion stricte de toutes les variables li√©es √† la target
excluded_columns = ['date', 'revenue', 'quantity', 'orders', 'customers', 
                   'revenue_ma_7', 'revenue_ma_30', 'revenue_trend', 'revenue_std_7']
feature_columns_safe = [col for col in modeling_data.columns if col not in excluded_columns]

print(f"üìä Features ORIGINALES: {len(feature_columns) if 'feature_columns' in locals() else 'N/A'}")
print(f"üìä Features S√âCURIS√âES: {len(feature_columns_safe)}")
print(f"üö´ Variables EXCLUES: {excluded_columns}")

features = modeling_data[feature_columns_safe]

print(f"\nüéØ Features utilis√©es pour l'entra√Ænement:")
for i, feature in enumerate(feature_columns_safe, 1):
    print(f"  {i:2d}. {feature}")

# V√©rification: aucune corr√©lation parfaite avec la target
correlations = features.corrwith(target).abs()
high_corr = correlations[correlations > 0.95]
if len(high_corr) > 0:
    print(f"\n‚ö†Ô∏è ALERTE: Corr√©lations suspectes d√©tect√©es!")
    print(high_corr)
else:
    print(f"\n‚úÖ Aucune corr√©lation parfaite d√©tect√©e")

# Division train/test (80/20) avec m√©lange pour √©viter le biais temporel
X_train, X_test, y_train, y_test = train_test_split(
    features, target, test_size=0.2, shuffle=True, random_state=42
)

print(f"\nüìä Taille de l'ensemble d'entra√Ænement: {len(X_train)} jours")
print(f"üìä Taille de l'ensemble de test: {len(X_test)} jours")

# V√©rification: pas de doublons entre train et test
overlap = set(X_train.index).intersection(set(X_test.index))
print(f"üìä Overlap train/test: {len(overlap)} (doit √™tre 0)")

# Normalisation des features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# D√©finition des mod√®les avec r√©gularisation
models = {
    'R√©gression Lin√©aire': LinearRegression(),
    'For√™t Al√©atoire': RandomForestRegressor(
        n_estimators=50,      # R√©duit pour √©viter surapprentissage
        max_depth=10,         # Limitation de profondeur
        min_samples_split=5,  # Minimum d'√©chantillons
        random_state=42, 
        n_jobs=-1
    )
}

# Entra√Ænement et √©valuation des mod√®les
results = {}
predictions = {}

for name, model in models.items():
    print(f"\nüîÑ Entra√Ænement du mod√®le: {name}")
    
    # Entra√Ænement
    if name == 'R√©gression Lin√©aire':
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_test_scaled)
    else:
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
    
    # M√©triques de performance
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    
    # V√©rification de la sanit√© des r√©sultats
    if r2 > 0.95:
        print(f"  ‚ö†Ô∏è ALERTE: R¬≤ = {r2:.3f} - Surapprentissage probable!")
    
    # Sauvegarde des r√©sultats
    results[name] = {
        'MSE': mse,
        'RMSE': rmse,
        'MAE': mae,
        'R¬≤': r2
    }
    
    predictions[name] = y_pred
    
    print(f"  ‚úÖ RMSE: {rmse:.2f}")
    print(f"  ‚úÖ MAE: {mae:.2f}")
    print(f"  ‚úÖ R¬≤: {r2:.3f}")

# Comparaison des mod√®les
print(f"\nüìä COMPARAISON DES MOD√àLES")
print("=" * 50)

comparison_df = pd.DataFrame(results).T
display(comparison_df.round(3))

# Analyse de la qualit√© des pr√©dictions
print(f"\nüéØ ANALYSE DE LA QUALIT√â:")
for name, r2_score_val in comparison_df['R¬≤'].items():
    if r2_score_val > 0.95:
        print(f"  ‚ö†Ô∏è {name}: R¬≤ = {r2_score_val:.3f} - SURAPPRENTISSAGE!")
    elif r2_score_val > 0.8:
        print(f"  ‚úÖ {name}: R¬≤ = {r2_score_val:.3f} - Tr√®s bon")
    elif r2_score_val > 0.6:
        print(f"  ‚úÖ {name}: R¬≤ = {r2_score_val:.3f} - Bon")
    else:
        print(f"  ‚ö†Ô∏è {name}: R¬≤ = {r2_score_val:.3f} - √Ä am√©liorer")

# Visualisation des pr√©dictions
fig = go.Figure()

# Cr√©ation d'un index temporel pour les dates de test
test_indices = X_test.index
test_dates = modeling_data.loc[test_indices, 'date']

# Valeurs r√©elles
fig.add_trace(go.Scatter(
    x=test_dates,
    y=y_test.values,
    mode='lines+markers',
    name='Valeurs R√©elles',
    line=dict(color='blue', width=2),
    marker=dict(size=6)
))

# Pr√©dictions de chaque mod√®le
colors = ['red', 'green']
for idx, (name, pred) in enumerate(predictions.items()):
    fig.add_trace(go.Scatter(
        x=test_dates,
        y=pred,
        mode='lines+markers',
        name=f'Pr√©dictions {name}',
        line=dict(color=colors[idx], width=2, dash='dash'),
        marker=dict(size=4)
    ))

fig.update_layout(
    title='Comparaison des Pr√©dictions vs Valeurs R√©elles (CORRIG√â)',
    xaxis_title='Date',
    yaxis_title='Chiffre d\'Affaires (‚Ç¨)',
    height=500,
    hovermode='x unified'
)
fig.show()

# Graphique des r√©sidus pour le meilleur mod√®le
best_model_name = comparison_df['R¬≤'].idxmax()
best_predictions = predictions[best_model_name]
residuals = y_test.values - best_predictions

fig_residuals = make_subplots(
    rows=1, cols=2,
    subplot_titles=('R√©sidus vs Pr√©dictions', 'Distribution des R√©sidus')
)

# R√©sidus vs Pr√©dictions
fig_residuals.add_trace(
    go.Scatter(x=best_predictions, y=residuals,
               mode='markers', name='R√©sidus',
               marker=dict(color='red', opacity=0.6)),
    row=1, col=1
)

# Ligne de r√©f√©rence √† y=0
fig_residuals.add_hline(y=0, line_dash="dash", line_color="black", row=1, col=1)

# Distribution des r√©sidus
fig_residuals.add_trace(
    go.Histogram(x=residuals, name='Distribution', nbinsx=20,
                marker=dict(color='lightblue', opacity=0.7)),
    row=1, col=2
)

fig_residuals.update_layout(height=400, showlegend=False, 
                          title_text=f"Analyse des R√©sidus - {best_model_name} (CORRIG√â)")
fig_residuals.show()

print(f"\nüèÜ Meilleur mod√®le: {best_model_name} (R¬≤ = {comparison_df.loc[best_model_name, 'R¬≤']:.3f})")

# Statistiques des r√©sidus
print(f"\nüìä STATISTIQUES DES R√âSIDUS:")
print(f"   Moyenne: {residuals.mean():.2f} (proche de 0 = bon)")
print(f"   √âcart-type: {residuals.std():.2f}")
print(f"   Min: {residuals.min():.2f}")
print(f"   Max: {residuals.max():.2f}")
```

### **3. Ex√©cuter Toutes les Cellules**

#### **Option A - Jupyter Notebook :**
- Menu : `Kernel` ‚Üí `Restart & Run All`

#### **Option B - VS Code :**
- Commande : `Ctrl+Shift+P` ‚Üí "Notebook: Run All"

#### **Option C - Ex√©cution manuelle :**
- Ex√©cutez chaque cellule une par une avec `Shift+Enter`

### **4. R√©sultats Attendus**

Apr√®s la correction, vous devriez voir :
```
‚úÖ RMSE: 1000-5000    (au lieu de 0.00)
‚úÖ MAE: 800-3000      (au lieu de 0.00)  
‚úÖ R¬≤: 0.60-0.85      (au lieu de 1.000)
```

### **5. En Cas de Probl√®me**

Si vous rencontrez des erreurs :
1. V√©rifiez que toutes les biblioth√®ques sont install√©es
2. Assurez-vous que le fichier `Online.xlsx` est pr√©sent
3. Red√©marrez le kernel et r√©ex√©cutez depuis le d√©but

---

## üéØ **OBJECTIF DE LA CORRECTION**

Cette modification √©limine le surapprentissage et produit des pr√©dictions **r√©alistes** et **g√©n√©ralisables** pour votre projet Yshop.
